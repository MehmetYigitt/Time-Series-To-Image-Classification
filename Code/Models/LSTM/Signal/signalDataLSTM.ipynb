{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, callbacks, models, optimizers\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "import yaml\n",
    "from attrdict import AttrDict\n",
    "from os import path\n",
    "from tqdm import tqdm\n",
    "from statistics import mean, stdev\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = path.join('..', '..', '..', '..', 'Data', 'UCI HAR Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('signalDataLSTMhparams.yaml') as params_file:\n",
    "    config = yaml.full_load(params_file)\n",
    "    hparams = AttrDict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_types = ['body_acc', 'body_gyro', 'total_acc']\n",
    "axis = ['x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(col_type, dataset_type):\n",
    "    if col_type == 'X':\n",
    "        dataset = list()\n",
    "        for sensor in sensor_types:\n",
    "            for direction in axis:\n",
    "                filepath = path.join(dataset_dir, dataset_type, '_'.join([sensor, direction, dataset_type])+'.csv')\n",
    "                dataset.append(pd.read_csv(filepath, delim_whitespace=True, header=None))\n",
    "        return np.array(np.dstack(dataset))\n",
    "    else:\n",
    "        y = pd.read_csv(path.join(dataset_dir, dataset_type, 'y_' + dataset_type + '.txt'), header=None)\n",
    "        return to_categorical(y-1)\n",
    "        # return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = get_dataset('X', 'train')\n",
    "y_train = get_dataset('y', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = get_dataset('X', 'test')\n",
    "y_test = get_dataset('y', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hparams, verbose=True):\n",
    "    model = models.Sequential()\n",
    "    model.add(keras.layers.Bidirectional(keras.layers.LSTM(hparams.neuron_count, activation=\"tanh\"), input_shape=(128, hparams.n_features)))\n",
    "    model.add(layers.Dropout(0.28))\n",
    "    model.add(layers.Dense(100))\n",
    "    model.add(layers.Dense(hparams.output_neuron, activation=\"softmax\"))\n",
    "    model.compile(optimizer=\"sgd\", loss=\"kullback_leibler_divergence\", metrics=[\"accuracy\"])\n",
    "    if verbose:\n",
    "        print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, 'model.png', show_shapes=True, show_dtype=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = callbacks.EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=5)\n",
    "model.fit(X_train, y_train, epochs=35, verbose=True,  validation_split=0.1, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate([X_test, means_test], y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(X_test)\n",
    "evaluation = list()\n",
    "for i in range(len(results)):\n",
    "    evaluation.append(str(np.argmax(results[i])+1) + '-' + str(np.argmax(y_test[i])+1))\n",
    "evals = pd.DataFrame(evaluation, columns=['eval'])\n",
    "evals.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stress Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', verbose=0, patience=5)\n",
    "accuracies = list()\n",
    "for i in tqdm(range(10)):\n",
    "    model = build_model(hparams, verbose=False)\n",
    "    model.fit(X_train, y_train, epochs=25, verbose=False,  validation_split=0.1, batch_size=64, callbacks=[es])\n",
    "    result = model.evaluate(X_test, y_test)[1]\n",
    "    accuracies.append(result)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"max: \", max(accuracies) * 100, \"\\nmin: \", min(accuracies) * 100, \"\\nmean: \", mean(accuracies), \"\\nstd: \", stdev(accuracies))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d77604b5305a708665e1df95d16b028ef698e61321d48de2b9f6d0bc9c05b8a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
